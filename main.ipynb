{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tools Recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Istallazione pacchetti se necessario.\n",
    "\n",
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pacchetti utilizzati.\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Raccolta e etichettatura delle immagini"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10 diverse categorie:\n",
    "    - accendino\n",
    "    - cacciavite\n",
    "    - chiave\n",
    "    - forbici\n",
    "    - martello\n",
    "    - metro\n",
    "    - nastro\n",
    "    - pappagallo\n",
    "    - penna\n",
    "    - spillatrice \n",
    "\n",
    "- 4 diverse superfici:\n",
    "    - tavolo bianco\n",
    "    - banco da lavoro\n",
    "    - pavimento di cemento\n",
    "    - coperta a righe\n",
    "- 20 immagini per il training per ogni categoria\n",
    "- 26 immagini per il test contenenti oggetti multipli e anche estranei alle 10 categorie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oggetti utilizzati.\n",
    "tool_names = ['accendino', 'cacciavite', 'chiave', 'forbici', 'martello', 'metro', 'nastro', 'pappagallo', 'penna', 'spillatrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rinomiamo le immagini nelle cartelle.\n",
    "cwd = os.getcwd()\n",
    "for tool in tool_names:\n",
    "    path = os.path.join(cwd, f\"images/{tool}/\")\n",
    "    image_files = glob.glob(path + '*.png')\n",
    "\n",
    "    for i, file in enumerate(image_files):\n",
    "        new_name = tool+ '_' + str(i+1) + '.png'\n",
    "        os.rename(file, os.path.join(path, new_name))\n",
    "\n",
    "\n",
    "# Rinominiamo le immagini del test set.\n",
    "path = os.path.join(cwd, f\"images/Test_set/\")\n",
    "image_files = glob.glob(path + '*.png')\n",
    "\n",
    "for i, file in enumerate(image_files):\n",
    "    new_name = 'test_' + str(i+1) + '.png'\n",
    "    os.rename(file, os.path.join(path, new_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Pre-elaborazione delle immagini"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ridimensionamento : portartiamo nello stesso formato tutte le immagini (520 x 520). Alcune delle utilità di questo passaggio possono essere una maggiore uniformità una volta che si va ad allenare l'algoritmo di calssificazione e l'aumento della diversità dei dati di training che possono portare il modello ad avere una maggiore robustezza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portiamo tutte le immagini nella stessa dimensione (520 x 520).\n",
    "cwd = os.getcwd()\n",
    "\n",
    "for tool in tool_names:\n",
    "    path = os.path.join(cwd, f\"images/{tool}/\")\n",
    "    image_files = glob.glob(path + '*.png')\n",
    "\n",
    "    for i, file in enumerate(image_files):\n",
    "        image = Image.open(file)\n",
    "\n",
    "        # Ridimensionamento dell'immagine.\n",
    "        resized_image = image.resize((520, 520))\n",
    "        resized_image.save(file)\n",
    "\n",
    "# test-set\n",
    "path = os.path.join(cwd, f\"images/Test_set/\")\n",
    "image_files = glob.glob(path + '*.png')\n",
    "\n",
    "for i, file in enumerate(image_files):\n",
    "    image = Image.open(file)\n",
    "\n",
    "    # Ridimensionamento dell'immagine.\n",
    "    resized_image = image.resize((520, 520))\n",
    "    resized_image.save(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Riduzione del rumore:  è finalizzata a migliorare la qualità dell'immagine, eliminando il rumore e aumentando il contrasto tra gli oggetti dell'immagine e lo sfondo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riduzione del rumore.\n",
    "cwd = os.getcwd()\n",
    "\n",
    "for tool in tqdm(tool_names):\n",
    "    folder_path = os.path.join(cwd, f\"images/{tool}/\")\n",
    "\n",
    "    for i in range(20):\n",
    "        path = f'{folder_path}/{tool}_{i+1}.png'\n",
    "        img = cv2.imread(path)\n",
    "\n",
    "        # Applicazione del filtro di riduzione del rumore.\n",
    "        img = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n",
    "        new_path = f'{folder_path}/{tool}_{i+1}.1.png'\n",
    "        cv2.imwrite(new_path, img)\n",
    "\n",
    "\n",
    "# test-set\n",
    "path = os.path.join(cwd, f\"images/Test_set/\")\n",
    "image_files = glob.glob(path + '*.png')\n",
    "\n",
    "for i, file in enumerate(image_files):\n",
    "    img = cv2.imread(file)\n",
    "\n",
    "    # Applicazione del filtro di riduzione del rumore.\n",
    "    img = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n",
    "    new_path = file[:-4] + '.1.png'\n",
    "    cv2.imwrite(new_path, img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eliminazione delle ombre: per gestire la presenza di ombre all'interno dei nostri dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminazione delle ombre.\n",
    "cwd = os.getcwd()\n",
    "\n",
    "for tool in tqdm(tool_names):\n",
    "    folder_path = os.path.join(cwd, f\"images/{tool}/\")\n",
    "\n",
    "    for i in range(20):\n",
    "        path = f'{folder_path}/{tool}_{i+1}.png'\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Applica soglia adattiva.\n",
    "        thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "        # Rimuove le ombre mascherando l'immagine con la soglia.\n",
    "        removed_shadows_img = cv2.bitwise_and(img, thresh)\n",
    "        new_path = f'{folder_path}/{tool}_{i+1}.1.png'\n",
    "        cv2.imwrite(new_path, removed_shadows_img)\n",
    "\n",
    "\n",
    "# test-set\n",
    "path = os.path.join(cwd, f\"images/Test_set/\")\n",
    "image_files = glob.glob(path + '*.1.png')\n",
    "\n",
    "for i, file in enumerate(image_files):\n",
    "    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Applica soglia adattiva.\n",
    "    thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Rimuove le ombre mascherando l'immagine con la soglia.\n",
    "    removed_shadows_img = cv2.bitwise_and(img, thresh)\n",
    "    cv2.imwrite(file, img)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Segmentazione delle immagini "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tecniche di segmentazione prese dalle slide:\n",
    "- per contorni:\n",
    "    - Canny edge detector\n",
    "    - Edge Linking\n",
    "    - Trasformata di Hough\n",
    "\n",
    "- per regioni:\n",
    "    - binarizzazione\n",
    "    - sogliatura automatica OTSU\n",
    "\n",
    "- mediante clustering:\n",
    "    - k-mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [METODO DI SEGMENTAZIONE UTILIZZATO]\n",
    "for tool in tqdm(tool_names):\n",
    "    folder_path = os.path.join(cwd, f\"images/{tool}/\")\n",
    "\n",
    "    for i in range(20):\n",
    "        path = f'{folder_path}/{tool}_{i+1}.png'\n",
    "        \n",
    "\n",
    "        # [PROCEDURA DI SEGMENTAZIONE]\n",
    "\n",
    "\n",
    "        new_path = f'{folder_path}/{tool}_{i+1}.2.png'\n",
    "        cv2.imwrite(new_path, removed_shadows_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = 'c:\\\\Users\\\\mcm23\\\\OneDrive\\\\Desktop\\\\GitHub\\\\Object_Detection\\\\images/metro/metro_16.1.png'\n",
    "path_2 = 'c:\\\\Users\\\\mcm23\\\\OneDrive\\\\Desktop\\\\GitHub\\\\Object_Detection\\\\images/martello/martello_4.1.png'\n",
    "path_3 = 'c:\\\\Users\\\\mcm23\\\\OneDrive\\\\Desktop\\\\GitHub\\\\Object_Detection\\\\images/nastro/nastro_12.1.png'\n",
    "path_4 = 'c:\\\\Users\\\\mcm23\\\\OneDrive\\\\Desktop\\\\GitHub\\\\Object_Detection\\\\images/cacciavite/cacciavite_8.1.png'\n",
    "path_5 = 'c:\\\\Users\\\\mcm23\\\\OneDrive\\\\Desktop\\\\GitHub\\\\Object_Detection\\\\images/pappagallo/pappagallo_9.1.png'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problemi:\n",
    "- ombre\n",
    "- sfondo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'spillatrice'\n",
    "for i in range(1,21):\n",
    "    path = f'c:\\\\Users\\\\mcm23\\\\OneDrive\\\\Desktop\\\\GitHub\\\\Object_Detection\\\\images/{t}/{t}_{i}.1.png'\n",
    "    path = f'c:\\\\Users\\\\mcm23\\\\OneDrive\\\\Desktop\\\\GitHub\\\\Object_Detection\\\\images/test_set/test_{i}.png'\n",
    "\n",
    "    ## Canny Edge Detector\n",
    "    # leggi l'immagine in scala di grigi\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Definizione del kernel di apertura\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "    # Applicazione dell'operatore di apertura\n",
    "    opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # visualizza l'immagine con i bordi individuatia\n",
    "    cv2.imshow('CANNY Edge Detector', opening)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[166, 166, 169, ..., 178, 178, 178],\n",
       "       [166, 166, 169, ..., 178, 178, 178],\n",
       "       [166, 166, 169, ..., 178, 178, 178],\n",
       "       ...,\n",
       "       [119, 119, 119, ..., 117, 117, 109],\n",
       "       [119, 119, 119, ..., 117, 117, 109],\n",
       "       [119, 119, 119, ..., 117, 117, 109]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = path_1\n",
    "\n",
    "\n",
    "## OTSU\n",
    "img = cv2.imread(new_path, cv2.IMREAD_GRAYSCALE)\n",
    "# Applica la sogliatura di Otsu\n",
    "_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Visualizza l'immagine segmentata\n",
    "cv2.imshow('OTSU', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "## Canny Edge Detector\n",
    "# leggi l'immagine in scala di grigi\n",
    "img = cv2.imread(new_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# applica il Canny Edge Detector con i parametri desiderati\n",
    "edges = cv2.Canny(img, threshold1=100, threshold2=200)\n",
    "\n",
    "# visualizza l'immagine con i bordi individuatia\n",
    "cv2.imshow('CANNY Edge Detector', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "## EDGE Linking\n",
    "img = cv2.imread(new_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# applica il Canny Edge Detector con i parametri desiderati\n",
    "edges = cv2.Canny(img, threshold1=200, threshold2=900)\n",
    "\n",
    "# applica la chiusura morfologica per unire i bordi\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "closed_edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# visualizza l'immagine con i bordi collegati\n",
    "cv2.imshow('Edges Linking', closed_edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Binarizzazione\n",
    "img = cv2.imread(new_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# applica la binarizzazione\n",
    "_, thresh = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# visualizza l'immagine binaria\n",
    "cv2.imshow('Binarized Image', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'accendino'\n",
    "\n",
    "new_path = os.path.join(cwd, f\"images/{a}/{a}_2.2.png\")\n",
    "img = cv2.imread(new_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Applica la sogliatura di Otsu\n",
    "_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Visualizza l'immagine segmentata\n",
    "cv2.imshow('Thresholded Image', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecco una possibile pipeline di elaborazione per un progetto di object detection utilizzando un modello di classificazione e un metodo di segmentazione:\n",
    "\n",
    "1) ``Raccolta dei dati``: Prima di iniziare qualsiasi progetto di object detection, è necessario raccogliere un dataset di immagini etichettate con le classi di oggetti di interesse. Il dataset deve essere rappresentativo delle varie condizioni di luce, sfondo e posizione degli oggetti.\n",
    "\n",
    "2) ``Pre-elaborazione dell'immagine``: L'immagine deve essere preparata per il successivo passaggio di segmentazione. Si può effettuare la riduzione del rumore o il bilanciamento del colore.\n",
    "\n",
    "3) ``Segmentazione dell'immagine``: Una volta ottenuto l'immagine preparata, si applica un metodo di segmentazione per dividere l'immagine in regioni omogenee. Si possono utilizzare tecniche di segmentazione come la segmentazione basata sulla soglia, la segmentazione basata sulla regione o la segmentazione basata sui contorni.\n",
    "\n",
    "4) ``Estrazione delle features``: Per ogni regione dell'immagine segmentata, si estraggono le feature utilizzate per addestrare il modello di classificazione. Le feature possono includere la forma, la texture, il colore o qualsiasi altra caratteristica che aiuti a distinguere le diverse classi di oggetti.\n",
    "\n",
    "5) ``Addestramento del modello di classificazione``: Una volta estratte le feature, si addestra il modello di classificazione utilizzando un algoritmo di machine learning come le reti neurali, le SVM o gli alberi di decisione. Il modello viene addestrato per riconoscere le diverse classi di oggetti.\n",
    "\n",
    "6) ``Rilevamento degli oggetti``: Una volta addestrato il modello di classificazione, si può applicare il modello all'immagine originale per rilevare gli oggetti di interesse. Utilizzando le feature estratte, il modello cerca le regioni dell'immagine che corrispondono agli oggetti di interesse.\n",
    "\n",
    "7) ``Post-elaborazione dell'immagine``: Una volta rilevati gli oggetti, si possono applicare tecniche di post-elaborazione come la non-maximum suppression per rimuovere i falsi positivi e migliorare la precisione del modello.\n",
    "\n",
    "In sintesi, la pipeline di elaborazione per un progetto di object detection con un modello di classificazione e un metodo di segmentazione consiste in: raccolta dei dati, pre-elaborazione dell'immagine, segmentazione dell'immagine, estrazione delle feature, addestramento del modello di classificazione, rilevamento degli oggetti e post-elaborazione dell'immagine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
